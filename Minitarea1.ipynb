{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:30:18.109327Z",
     "start_time": "2020-03-19T18:30:18.103344Z"
    }
   },
   "source": [
    "# Minitarea 1\n",
    "\n",
    "\n",
    "-----------------\n",
    "\n",
    "Nombre: Miguel Videla A.\n",
    "\n",
    "Fecha de Entrega: Lunes 6 de Abril\n",
    "\n",
    "\n",
    "## Objetivos de la minitarea\n",
    "\n",
    "Este ejericio cuenta con varios objetivos principales: \n",
    "\n",
    "- Evaluar los contenidos de las primeras semanas de clases. En particular Information Retrieval (IR) y Vector Space Models. \n",
    "\n",
    "- Introducirlos a la programación en python enfocada en NLP.\n",
    "\n",
    "- Implementar un modelo básico de IR: *Term Frequency-Inverse Document Frequency (TF-IDF)*.\n",
    "\n",
    "\n",
    "## Instrucciones\n",
    "\n",
    "- El ejercicio consiste en:\n",
    "\n",
    "    - Responder preguntas relativas a los contenidos vistos en los videos y slides de las clases. \n",
    "    \n",
    "    - Implementar el modelo TF-IFD utilizando solo python, pandas y numpy. Está **PROHIBIDO** usar cualquier paquete que implemente dicho modelo (NLTK, spacy, scikit, etc...).\n",
    "\n",
    "- La minitarea es INDIVIDUAL.\n",
    "\n",
    "- Está demás decir que no se admiten copias, ni de código, ni de respuestas escritas. \n",
    "\n",
    "- La entrega debe ser por ucursos a mas tardar el día estipulado arriba. No se aceptan atrasos.\n",
    "\n",
    "- En el horario de auxiliar se abriran horarios de consulta en donde podrán preguntar acerca del ejercicio y en general, de todo el curso. \n",
    "\n",
    "- Cada punto equivale a 0.5 décimas de la nota de la minitarea.\n",
    "\n",
    "- Al revisar, tu código será ejecutado. Verifica que tu entrega no tenga errores.\n",
    "\n",
    "\n",
    "## Referencias\n",
    " \n",
    "Slides:\n",
    "    \n",
    "- [Introducción al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n",
    "- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n",
    "\n",
    "Videos: \n",
    "\n",
    "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 1](https://youtu.be/FXIVClF370w)\n",
    "- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 2](https://youtu.be/f8nG1EMmPZk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "## Parte 1. \n",
    "\n",
    "La siguientes celdas contendrán preguntas acerca del contenido visto en clases y en el material del curso. La idea es contestar cada pregunta en su celda correspondiente. Las respuestas deben ser breves: máximo 3 lineas (salvo para la p3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P1) Son Natural Language Processing y Computational Linguistics lo mismo? (1 Punto)**\n",
    "\n",
    "    Respuesta: \n",
    "    No, ambos conceptos difieren en su foco de estudio. Natural Lenguage Processing se centra en la resolución de tareas bien determinadas que involucran el lenguaje humano, tales como traducción, consultas sobre texto, etc., mientras que Computational Linguistics se centra en el estudio del lenguaje (lingüística) apoyado por métodos computacionales.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P2) Por qué estudiar el lenguaje humano es difícil? (1 Punto)**\n",
    "\n",
    "    Respuesta: \n",
    "    Debido a su gran diversidad y amplia extensión, resulta extremadamente complicado establecer reglas formales que lo describan cabalmente. La complejidad del lenguaje humano recae en tres de sus propiedades: La discreción, que hace referencia a la imposibilidad de establecer relaciones entre dos palabras mediantes las letras que las componen; La composición, que hace referencia a la diferencia de signficado de una oración con respecto al significado las palabras que la componen; La dispersión, que hace referencia a la infinidad de significados que puede poseer un texto generado en base a la combinación de distintas palabras. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:45:25.544502Z",
     "start_time": "2020-03-19T18:45:25.537548Z"
    }
   },
   "source": [
    "\n",
    "**P3) Para el siguiente corpus:**\n",
    "\n",
    "    d1) I like human languages\n",
    "\n",
    "    d2) I like programming languages\n",
    "\n",
    "    d3) Spanish is my favorite language\n",
    "\n",
    "\n",
    "**Extraiga el vocabulario:**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Solamente usando tokenization (1.5 puntos)**\n",
    "\n",
    "Respuesta: \n",
    "\n",
    "        Vocabulario: ['I', 'like', 'human', 'languages', 'programming', 'Spanish', 'is', 'my', 'favorite', 'language']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Usando stemming (proponga sus propias reglas de stemming) y borrado de stopwords (indique cuales son sus stopwords) (1.5 puntos)**\n",
    "\n",
    "Respuesta: \n",
    "\n",
    "        Stopwords: ['I', 'is', 'my']\n",
    "        \n",
    "        Reglas de Stemming: [['ES'->'S']]\n",
    "        \n",
    "        Vocabulario: ['like', 'human', 'language', 'programming', 'Spanish', 'favorite']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:46:24.015666Z",
     "start_time": "2020-03-19T18:46:24.010706Z"
    }
   },
   "source": [
    "**P4) Conceptualmente cuál es la diferencia entre usar machine learning clásico (empirismo) y deep learning para un problema de NLP (Puede usar el análisis de sentimientos como ejemplo) (1 punto)**\n",
    "\n",
    "    Respuesta: \n",
    "    ML clásico utiliza un amplio conjunto de reglas empíricas en la determinación de características relevantes para su posterior procesamiento (Ej: Contar la recurrencia de palabras con diminutivos para clasificar un texto como amable), mientras que en DL los modelos aprenden a determinar/extraer las características más relevantes de los propios datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:47:04.360754Z",
     "start_time": "2020-03-19T18:47:04.357763Z"
    }
   },
   "source": [
    "--------------\n",
    "\n",
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-19T18:57:05.868104Z",
     "start_time": "2020-03-19T18:57:05.863117Z"
    }
   },
   "source": [
    "Impementar TF-IDF. \n",
    "\n",
    "Esta parte, cada celda representa una función distinta por implementar. Se usará pandas para representar las matrices y arreglos que vayamos calculando. Siguiente a cada celda con una función por implementar habrá un ejemplo de como debería ser el output que tienen que lograr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.618054Z",
     "start_time": "2020-03-23T14:11:57.813136Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Corpus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset, cada string representa un documento. Observación: Corpus = Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.637916Z",
     "start_time": "2020-03-23T14:11:58.618054Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    't4 t3 t1 t4', 't5 t4 t2 t3 t5', 't2 t1 t4 t4', 't2 t3 t3 t1 t4',\n",
    "    't1 t4 t2 t2', 't2 t3 t2 t3 t2 t3'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtener vocabulario (1 punto)** \n",
    "\n",
    "Implementar la función `get_vocab(dataset)` que recibe el dataset y retorna un arreglo con cada palabra que aparece en el dataset. (sin duplicar). Observación: vocabulario = types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.657732Z",
     "start_time": "2020-03-23T14:11:58.637916Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vocab(dataset):\n",
    "    words = ''\n",
    "    for sentence in dataset:\n",
    "        words += ' ' + sentence\n",
    "    words = list(set(words.split()))\n",
    "    words.sort()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.671780Z",
     "start_time": "2020-03-23T14:11:58.657732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t1', 't2', 't3', 't4', 't5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = get_vocab(dataset)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular Bag of Words (bow) (2 puntos)**\n",
    "\n",
    "implementar la función `calc_bow(dataset, vocab)` que toma el dataset y el vocabulario calculado en la parte anterior y retorna un pandas DataFrame en donde las columnas son el vocabulario y las filas representa las apariciones de cada una de las palabra los documento. En otras palabras, cada fila representa el bow de un determinado documento\n",
    "\n",
    "el bow de cada documento.\n",
    "\n",
    "Recordatorio - Bag of Words: Cuenta las apariciones de cada palabra en cada uno de los documentos. Por ejemplo:\n",
    "\n",
    "Por ejemplo, para los documentos: \n",
    "\n",
    "```\n",
    "d_0 = 'El perro ladra'\n",
    "d_1 = 'El perro come'\n",
    "\n",
    "```\n",
    "\n",
    "Deberíamos retornar:\n",
    "\n",
    "|   | el | perro | ladra | come |\n",
    "|---|----|-------|------|-------|\n",
    "| d_0 | 1  | 1     | 1    | 0     |\n",
    "| d_1 | 1  | 1     | 0    | 1     |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.680740Z",
     "start_time": "2020-03-23T14:11:58.673758Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_bow(dataset, vocab):\n",
    "    counts = []\n",
    "    for sentence in dataset:\n",
    "        dic = dict.fromkeys(vocab, 0)\n",
    "        for word in sentence.split():\n",
    "            dic[word] += 1\n",
    "        counts.append(list(dic.values()))\n",
    "    return pd.DataFrame(counts, columns=vocab)\n",
    "\n",
    "dataset_bow = calc_bow(dataset, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.694719Z",
     "start_time": "2020-03-23T14:11:58.683734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t1  t2  t3  t4  t5\n",
       "0   1   0   1   2   0\n",
       "1   0   1   1   1   2\n",
       "2   1   1   0   2   0\n",
       "3   1   1   2   1   0\n",
       "4   1   2   0   1   0\n",
       "5   0   3   3   0   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T14:27:01.721767Z",
     "start_time": "2020-03-20T14:27:01.716781Z"
    }
   },
   "source": [
    "**Calcular TF (1 punto)**\n",
    "\n",
    "En esta sección debemos usar el dataframe calcular la matriz de TF normalizada por el máximo $\\text{ntf}_{i,j}$. Es decir, dividir cada bow en la cantidad de veces de la palabra que aparezca mas veces ese vector. \n",
    "\n",
    "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{max_i({\\text{tf}_{i,j})}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.717795Z",
     "start_time": "2020-03-23T14:11:58.697765Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_tf(dataset_bow):\n",
    "    return dataset_bow.divide(dataset_bow.max(axis=1), axis=0) \n",
    "\n",
    "tf = calc_tf(dataset_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.737943Z",
     "start_time": "2020-03-23T14:11:58.717795Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    t1   t2   t3   t4   t5\n",
       "0  0.5  0.0  0.5  1.0  0.0\n",
       "1  0.0  0.5  0.5  0.5  1.0\n",
       "2  0.5  0.5  0.0  1.0  0.0\n",
       "3  0.5  0.5  1.0  0.5  0.0\n",
       "4  0.5  1.0  0.0  0.5  0.0\n",
       "5  0.0  1.0  1.0  0.0  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular IDF (1 punto)**\n",
    "\n",
    "\n",
    "Implementar `calc_idf(dataset_bow)`. Este debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el calculo de cada idf por palabra.\n",
    "\n",
    "Recordar que $idf_{t_i} = log_{10}\\frac{N}{n_i}$ con $N = $ número de documentos y $n_i = $ Número de documentos que contienen la palabra $t_i$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.777595Z",
     "start_time": "2020-03-23T14:11:58.737943Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_idf(dataset_bow):\n",
    "    dic = dict()\n",
    "    mask = (dataset_bow != 0)\n",
    "    for word in mask.columns:\n",
    "        dic[word] = np.log10(mask.shape[0] / mask[word].sum())\n",
    "    return dic\n",
    "\n",
    "idf = calc_idf(dataset_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.792834Z",
     "start_time": "2020-03-23T14:11:58.777595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t1': 0.17609125905568124,\n",
       " 't2': 0.07918124604762482,\n",
       " 't3': 0.17609125905568124,\n",
       " 't4': 0.07918124604762482,\n",
       " 't5': 0.7781512503836436}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcular TF-IDF (1 punto)**\n",
    "\n",
    "Por último, implementar `calc_tf_idf(tf, idf)`. Esta debe cumplir que \n",
    "\n",
    "$$tf{-}idf = tf_{i,j} * idf_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.817896Z",
     "start_time": "2020-03-23T14:11:58.792834Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_tf_idf(tf, idf):\n",
    "    for word in tf.columns:\n",
    "        tf[word] *= idf[word]\n",
    "    return tf\n",
    "        \n",
    "\n",
    "tf_idf = calc_tf_idf(tf, idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:58.837641Z",
     "start_time": "2020-03-23T14:11:58.817896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.079181</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.778151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079181</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.176091</td>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088046</td>\n",
       "      <td>0.079181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039591</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079181</td>\n",
       "      <td>0.176091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         t1        t2        t3        t4        t5\n",
       "0  0.088046  0.000000  0.088046  0.079181  0.000000\n",
       "1  0.000000  0.039591  0.088046  0.039591  0.778151\n",
       "2  0.088046  0.039591  0.000000  0.079181  0.000000\n",
       "3  0.088046  0.039591  0.176091  0.039591  0.000000\n",
       "4  0.088046  0.079181  0.000000  0.039591  0.000000\n",
       "5  0.000000  0.079181  0.176091  0.000000  0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus: Hacer una función para realizar una Query (2 puntos extra)**\n",
    "\n",
    "`calc_query(query, dataset)` función debe retornar un ranking con los documentos mas relevantes para la palabra consultada. \n",
    "\n",
    "Sugerencias:\n",
    "\n",
    "- Primero, recalcular la matriz TF-IDF usando el dataset mas la query. Usen las funciones anteriores para calcular la matriz.\n",
    "- Luego, usar similitud coseno para comparar los documentos ya precalculados y la consulta. (deben implementar dicha función usando las herramientas básicas de numpy).\n",
    "- A partir de eso, retornar un ranking con los documentos mas similares.\n",
    "\n",
    "Deben reportar por lo menos 2 ejemplos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T13:06:17.829181Z",
     "start_time": "2020-03-24T13:06:17.825192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: \"El perro ladra\"\n",
      "Ranked documents: [0 1 2 3 4 5]\n",
      "Query: \"El t5 ladra\"\n",
      "Ranked documents: [1 0 2 3 4 5]\n",
      "Query: \"t2 t3 t2 t3 t2 t3\"\n",
      "Ranked documents: [5 3 0 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.multiply(vec1, vec2).sum() / (np.sqrt(np.power(vec1, 2).sum()) * np.sqrt(np.power(vec2, 2).sum()))\n",
    "\n",
    "def calc_query(query, dataset):\n",
    "    dataset = dataset + [query]\n",
    "    vocab = get_vocab(dataset)\n",
    "    dataset_bow = calc_bow(dataset, vocab)\n",
    "    tf = calc_tf(dataset_bow)\n",
    "    idf = calc_idf(dataset_bow)\n",
    "    tf_idf = calc_tf_idf(tf, idf)\n",
    "    similarities = []\n",
    "    for i in range(tf_idf.shape[0] - 1):\n",
    "        similarities.append(cosine_similarity(tf_idf.iloc[i].to_numpy(), tf_idf.iloc[-1].to_numpy()))\n",
    "    return np.argsort(-np.array(similarities))\n",
    "\n",
    "queries = ['El perro ladra', 'El t5 ladra', 't2 t3 t2 t3 t2 t3']\n",
    "for query in queries:\n",
    "    print('Query: \"{}\"'.format(query))\n",
    "    print('Ranked documents: {}'.format(calc_query(query, dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usar dato reales (Opcional, sin puntaje)**\n",
    "\n",
    "Adicionalmente, existe la alternativa de probar tu implementación de tf-idf con un dataset de noticias:\n",
    "\n",
    "El modelo que creaste anteriormente no debería dejar de funcionar si cargas este dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T14:11:42.470019Z",
     "start_time": "2020-03-23T14:11:33.935341Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "BASE_URL = 'https://github.com/dccuchile/CC6205/releases/download/Data/{}.json'\n",
    "\n",
    "dataset = pd.concat([\n",
    "    pd.read_json(BASE_URL.format('biobio_nacional')),\n",
    "    pd.read_json(BASE_URL.format('biobio_opinion')),\n",
    "    pd.read_json(BASE_URL.format('biobio_internacional')),\n",
    "    pd.read_json(BASE_URL.format('biobio_sociedad')),\n",
    "    pd.read_json(BASE_URL.format('biobio_economia'))\n",
    "])\n",
    "\n",
    "\n",
    "def clean_doc(doc):\n",
    "    return ' '.join(\n",
    "        list(\n",
    "            filter(\n",
    "                lambda x: x != '',\n",
    "                re.sub(\"\\?|\\¿|\\:|\\!|\\¡|\\(|\\)|\\t|\\n|“|”|\\\"|\\'|\\s\\s+|\\.|\\,|\\;\",\n",
    "                       \" \", doc.lower()).split(' '))))\n",
    "\n",
    "\n",
    "dataset = list(\n",
    "    map(lambda x: clean_doc(x[0] + '.' + x[1]), dataset[['title',\n",
    "                                                         'content']].values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
